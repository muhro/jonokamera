<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Metropolia jonokamera</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="main.css">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.2"></script>
    <!-- Load BodyPix -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.0"></script>
    <script src="models/face-api.min.js"></script>
    <link rel="shortcut icon" type="image/png" href="img/MP-favicon.png"/>
    <script>

    </script>
</head>
<body onload="choiceFunction(); choiceKampus();">
<header class="headerC">
    <img src="img/MP-logo.png" class="img">
    <h1 class="kampus" id="kampus">Kampus<span class="triangle"></span></h1>
    <div class="dropdown">
        <div class="list" id="kampuslista" style="display: none">
            <h1 class="choice 152" id="152">Leiritie<span class="triangle"></span></h1>
            <h1 class="choice 153" id="153">HÃ¤meentie<span class="triangle"></span></h1>
            <h1 class="choice 158" id="158">Myllypuro<span class="triangle"></span></h1>
            <h1 class="choice 154" id="154">Vanha viertotie<span class="triangle"></span></h1>
        </div>
    </div>


</header>
<div class="leftDiv">
    <div class="otsikko">
        <img class="thumb" src="img/jono-img.png">
        <h2 class="otsikkoH1">RUOKALAN JONO</h2>
    </div>
    <div class="ruokalanjono">
        <canvas width="720" height="560" id="canvas" class="canvas"></canvas>
        <video class="video" id="video" width="720" height="560" autoplay muted loop src="img/testivideo4.mp4">
        </video>
    </div>
</div>
<div class="rightDiv">
    <div class="otsikko">
        <img class="thumb" src="img/ruokalista-img.png">
        <h2 class="otsikkoH1">RUOKALISTA</h2>
    </div>
    <div class="ruokalista">
        <div class="moi" id="ruokaLista">
        </div>
    </div>
</div>


</body>
<script>

  Promise.all([
    faceapi.nets.tinyFaceDetector.loadFromUri('./models'),
    faceapi.nets.faceLandmark68Net.loadFromUri('./models'),
    faceapi.nets.faceRecognitionNet.loadFromUri('./models'),
    faceapi.nets.faceExpressionNet.loadFromUri('./models'),
  ]);

  loadAndPredict();

 // const img = document.getElementById('video');
 // const video = document.getElementById('video');
  async function loadAndPredict() {

    setInterval(async () => {
      document.getElementById('video').style.filter = 'blur(3px)';
    //  document.getElementById('video').style.opacity = '0';
    },30);

   /*
----------------------------------------------------------------------------------
|    This site does not need anything installed                                  |
|                                                                                |
|    It requires links in <head> and the faceAPI file in /models                 |
|    BodyPix/faceAPI documentation are good and easy to use                      |
|     and the SetInterval(async () => { },30);                                   |
|     above should be commented out if you are going to use BodyPix/faceAPI      |
|     and take the commented video opacity out of comments                       |
|     so the SetInterval only hides the original video stream                    |
|     code draws canvas on top of the video element and hides the video element  |
|     in the canvas faceAPI/BodyPix draws blur/colors so it will look like blur  |
|--------------------------------------------------------------------------------|
|    LoadAndPredict function have two different function to use                  |
|    Both require the const net = await bodyPix.load({}) marked below            |
|    and the setInterval(async () => { },60);                                    |
|--------------------------------------------------------------------------------|
|    Blurry :                                                                    |
|    Blurs the people tensorFlow finds                                           |
|    in the blurring there is array of numbers and each number means different   |
|    body part so you can decide what parts do you want the code to search       |
|--------------------------------------------------------------------------------|
|    Color :                                                                     |
|    Color the people tensorFlow finds , marks body parts with different colors  |
|    You can find the body part IDs in BodyPixs Documentation                    |
|--------------------------------------------------------------------------------|
|    Main.js and app.js make the Sodexo food JSON work                           |
|--------------------------------------------------------------------------------|
|          All the blurring and menu stuff are done here                         |
|              below the BodyPix/FaceAPI stuff                                   |
|                                                                                |
|                                                                                |
----------------------------------------------------------------------------------


    const net = await bodyPix.load({
      architecture: 'MobileNetV1',
      outputStride: 16,
      multiplier: 0.5,
      quantBytes: 4,

    });*/




   /* setInterval(async () => {
      /* BLURRY

      const partSegmentation = await net.segmentMultiPersonParts(img);

      const backgroundBlurAmount = 3;
      const edgeBlurAmount = 3;
      const flipHorizontal = false;
      const faceBodyPartIdsToBlur = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24];
      const canvas = document.getElementById('canvas');

      const displaySize = {width: video.width, height: video.height};
      faceapi.matchDimensions(canvas, displaySize);

      canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
      bodyPix.blurBodyPart(
          canvas, img, partSegmentation, faceBodyPartIdsToBlur,
          backgroundBlurAmount, edgeBlurAmount, flipHorizontal);
       */

      /* COLOR

        const partSegmentation = await net.segmentMultiPersonParts(img);

        const coloredPartImage = bodyPix.toColoredPartMask(partSegmentation);
        const opacity = 0.7;
        const flipHorizontal = false;
        const maskBlurAmount = 0;
        const canvas = document.getElementById('canvas');

        const displaySize = {width: video.width, height: video.height};
        faceapi.matchDimensions(canvas, displaySize);

        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
        bodyPix.drawMask(
            canvas, img, coloredPartImage, opacity, maskBlurAmount,
            flipHorizontal);
        */
  //  }, 30);
  }

  function choiceFunction() {
    document.getElementById('kampus').addEventListener('click',() => {
      if (document.getElementById('kampuslista').style.display === 'inline-flex') {
        document.getElementById('kampuslista').style.display = 'none';
      } else if (document.getElementById('kampuslista').style.display === 'none') {
        document.getElementById('kampuslista').style.display = 'inline-flex';
      }
    });
  }

  function choiceKampus() {

    let kampusButtons = document.getElementById('kampuslista');

    kampusButtons.addEventListener('click', (event) => {
      let innerHtml = event.target || event.srcElement;
      document.getElementById('kampus').innerHTML = innerHtml.innerHTML;

      document.getElementById('kampuslista').style.display = 'none';

    });
  }

  document.getElementById('152').addEventListener('click', ()=>{
      document.getElementById('video').src = 'img/testivideo4.mp4';
    document.getElementById('kampus').style.width = '8vw';
      console.log('152');
  })
  document.getElementById('153').addEventListener('click', ()=>{
      document.getElementById('video').src = 'img/testivideo2.mp4';
    document.getElementById('kampus').style.width = '12vw';
      console.log('153');
  })
  document.getElementById('158').addEventListener('click', ()=>{
      document.getElementById('video').src = 'img/testivideo3.mp4';
    document.getElementById('kampus').style.width = '8vw';
      console.log('158');
  })
  document.getElementById('154').addEventListener('click', ()=>{
      document.getElementById('video').src = 'img/testivideo.mp4';
    document.getElementById('kampus').style.width = '22vw';
      console.log('154');
  })



</script>
<script src="main.js"></script>


</html>